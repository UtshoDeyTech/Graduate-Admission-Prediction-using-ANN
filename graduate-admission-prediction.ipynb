{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d9c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3a3c48",
   "metadata": {
    "papermill": {
     "duration": 0.032547,
     "end_time": "2022-12-11T14:22:19.327538",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.294991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0416733",
   "metadata": {
    "papermill": {
     "duration": 0.036676,
     "end_time": "2022-12-11T14:22:19.369756",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.333080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a946128c",
   "metadata": {
    "papermill": {
     "duration": 0.019237,
     "end_time": "2022-12-11T14:22:19.395348",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.376111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe036cc",
   "metadata": {
    "papermill": {
     "duration": 0.027316,
     "end_time": "2022-12-11T14:22:19.428666",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.401350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863402bc",
   "metadata": {
    "papermill": {
     "duration": 0.019783,
     "end_time": "2022-12-11T14:22:19.454340",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.434557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:8]\n",
    "y = df.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a45533",
   "metadata": {
    "papermill": {
     "duration": 0.024334,
     "end_time": "2022-12-11T14:22:19.484504",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.460170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0        337          118                  4  4.5   4.5  9.65         1\n",
       "1        324          107                  4  4.0   4.5  8.87         1\n",
       "2        316          104                  3  3.0   3.5  8.00         1\n",
       "3        322          110                  3  3.5   2.5  8.67         1\n",
       "4        314          103                  2  2.0   3.0  8.21         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989d59a6",
   "metadata": {
    "papermill": {
     "duration": 1.074685,
     "end_time": "2022-12-11T14:22:20.566238",
     "exception": false,
     "start_time": "2022-12-11T14:22:19.491553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6d97e8",
   "metadata": {
    "papermill": {
     "duration": 0.015737,
     "end_time": "2022-12-11T14:22:20.588276",
     "exception": false,
     "start_time": "2022-12-11T14:22:20.572539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3635245e",
   "metadata": {
    "papermill": {
     "duration": 0.023538,
     "end_time": "2022-12-11T14:22:20.618497",
     "exception": false,
     "start_time": "2022-12-11T14:22:20.594959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afc2de",
   "metadata": {
    "papermill": {
     "duration": 0.005851,
     "end_time": "2022-12-11T14:22:20.632137",
     "exception": false,
     "start_time": "2022-12-11T14:22:20.626286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ANN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3f37b3",
   "metadata": {
    "papermill": {
     "duration": 6.761415,
     "end_time": "2022-12-11T14:22:27.399700",
     "exception": false,
     "start_time": "2022-12-11T14:22:20.638285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecce4fd5",
   "metadata": {
    "papermill": {
     "duration": 0.147328,
     "end_time": "2022-12-11T14:22:27.553230",
     "exception": false,
     "start_time": "2022-12-11T14:22:27.405902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation ='relu',input_dim=7))\n",
    "model.add(Dense(7,activation ='relu'))\n",
    "model.add(Dense(1,activation ='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684e83a8",
   "metadata": {
    "papermill": {
     "duration": 0.017559,
     "end_time": "2022-12-11T14:22:27.577103",
     "exception": false,
     "start_time": "2022-12-11T14:22:27.559544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53be6ae3",
   "metadata": {
    "papermill": {
     "duration": 0.024155,
     "end_time": "2022-12-11T14:22:27.607385",
     "exception": false,
     "start_time": "2022-12-11T14:22:27.583230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer = \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7dec55",
   "metadata": {
    "papermill": {
     "duration": 29.237819,
     "end_time": "2022-12-11T14:22:56.851432",
     "exception": false,
     "start_time": "2022-12-11T14:22:27.613613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 2s 35ms/step - loss: 1.4414 - accuracy: 0.0000e+00 - val_loss: 1.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.1290 - accuracy: 0.0000e+00 - val_loss: 0.9872 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9087 - accuracy: 0.0000e+00 - val_loss: 0.8043 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.7527 - accuracy: 0.0000e+00 - val_loss: 0.6674 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6262 - accuracy: 0.0000e+00 - val_loss: 0.5577 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.0000e+00 - val_loss: 0.4620 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4277 - accuracy: 0.0000e+00 - val_loss: 0.3784 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.0000e+00 - val_loss: 0.3007 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2630 - accuracy: 0.0000e+00 - val_loss: 0.2296 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.0000e+00 - val_loss: 0.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.1196 - accuracy: 0.0000e+00 - val_loss: 0.0800 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0586 - accuracy: 0.0000e+00 - val_loss: 0.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0175 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 0.0000e+00 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0071 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=500,validation_split = 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fd548b-ff7a-4a86-a63b-df5bdd345958",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93180d4-b529-4b04-90ae-23288f67e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(acc, color='r', label='Training acc')\n",
    "plt.plot(val_acc, color='g', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(loss, color='r', label='Training loss')\n",
    "plt.plot(val_loss, color='g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b2b73e",
   "metadata": {
    "papermill": {
     "duration": 0.224836,
     "end_time": "2022-12-11T14:22:57.145237",
     "exception": false,
     "start_time": "2022-12-11T14:22:56.920401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0178680e",
   "metadata": {
    "papermill": {
     "duration": 0.077624,
     "end_time": "2022-12-11T14:22:57.289233",
     "exception": false,
     "start_time": "2022-12-11T14:22:57.211609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.8085682025478838\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score, accuracy_score\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,r2_score(y_test,y_pred))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mF:\\04. Machine Learning Projects\\mlProjects\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mF:\\04. Machine Learning Projects\\mlProjects\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mF:\\04. Machine Learning Projects\\mlProjects\\lib\\site-packages\\sklearn\\metrics\\_classification.py:106\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"r2_score\",r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0c5c7",
   "metadata": {
    "papermill": {
     "duration": 0.066943,
     "end_time": "2022-12-11T14:22:57.422776",
     "exception": false,
     "start_time": "2022-12-11T14:22:57.355833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecc0fb",
   "metadata": {
    "papermill": {
     "duration": 0.067367,
     "end_time": "2022-12-11T14:22:57.558277",
     "exception": false,
     "start_time": "2022-12-11T14:22:57.490910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlProject",
   "language": "python",
   "name": "mlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.162201,
   "end_time": "2022-12-11T14:23:00.400945",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-11T14:22:10.238744",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
